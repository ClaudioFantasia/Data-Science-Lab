{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZL-jzk54Zat"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "#import pingouin as pg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def removingOutlierColumn(col,df,fact = 1.5):\n",
        "  #fact usually should be 1.5\n",
        "  q1 = df[col].quantile(0.25)    # First Quartile\n",
        "  q3 = df[col].quantile(0.75)    # Third Quartile\n",
        "  IQR = q3 - q1                            # Inter Quartile Range\n",
        "\n",
        "  llimit = q1 - fact*IQR                       # Lower Limit\n",
        "  ulimit = q3 + fact*IQR                        # Upper Limit\n",
        "\n",
        "  outliers = df[(df[col] < llimit) | (df[col] > ulimit)]\n",
        "\n",
        "  df.drop(outliers.index, axis = 0, inplace = True)\n",
        "\n",
        "\n",
        "  print('Number of outliers in \"' + col + ' : ' + str(len(outliers)))\n",
        "  print(llimit)\n",
        "  print(ulimit)\n",
        "  print(IQR)\n",
        "\n",
        "def findImportance(df):\n",
        "  X = df\n",
        "  y = df['shares']\n",
        "  feature_list = []\n",
        "  df.drop('shares', axis = 1, inplace = True)\n",
        "  reg = RandomForestRegressor(100, random_state=42)\n",
        "  reg.fit(X, y)\n",
        "  df[\"shares\"] = y\n",
        "  feature_dict = dict(sorted(zip(df.columns, reg.feature_importances_), key=lambda x: x[1],reverse=True))\n",
        "  temp = feature_dict.keys()\n",
        "  for key in temp:\n",
        "    feature_list.append(key)\n",
        "  return feature_dict,feature_list"
      ],
      "metadata": {
        "id": "Bun3Uhwp4pgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initializing the dataset\n",
        "path_dev = \"./development.csv\"\n",
        "df = pd.read_csv(path_dev)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "\n",
        "\n",
        "##  Deleting silly columns\n",
        "df.drop(['url','id','timedelta'], axis = 1, inplace = True)\n",
        "#   Remove strange outliers with some data with 0 values\n",
        "mask = (df['average_token_length'] == 0) & (df['n_tokens_content'] == 0)\n",
        "df.drop(df[mask].index, axis = 0, inplace = True)\n",
        "\n",
        "\n",
        "##Filling NaN values in num_imgs and num_videos using zero\n",
        "NaN_columns = ['num_imgs','num_videos']\n",
        "for el in NaN_columns:\n",
        "    mean_values = df.groupby('data_channel')[el].mean()\n",
        "    # Iterate over each group and fill NaN values with the corresponding mean\n",
        "    for group, mean in mean_values.items():\n",
        "      df.loc[df['data_channel'] == group, el] = df.loc[df['data_channel'] == group, el].fillna(0)\n",
        "\n",
        "##  filling NaN values in num_keywords grouping by 'data_channel' and calculate the mean\n",
        "mean_values = df.groupby('data_channel')[\"num_keywords\"].mean()\n",
        "for group, mean in mean_values.items():\n",
        "  df.loc[df['data_channel'] == group, \"num_keywords\"] = df.loc[df['data_channel'] == group, \"num_keywords\"].fillna(mean)\n",
        "\n",
        "##  Transforming several features into a normal distribution shape using logaritmic transformation\n",
        "logTransformation = ['n_tokens_content','num_hrefs','num_self_hrefs','num_imgs','num_videos','kw_max_min','kw_avg_min','kw_min_max','kw_min_avg','kw_max_max','kw_max_avg','kw_avg_avg','self_reference_min_shares','self_reference_max_shares']\n",
        "df[logTransformation] = np.log(1.001 + df[logTransformation])\n",
        "\n",
        "#removingOutlierColumn('average_token_length',df, fact = 1.5)\n",
        "removingOutlierColumn('shares',df, fact = 8)\n",
        "removingOutlierColumn('kw_avg_avg',df,1.5)\n",
        "removingOutlierColumn(\"self_reference_avg_sharess\",df,4)\n",
        "#removingOutlierColumn('kw_avg_avg',df,fact = 6)\n",
        "#removingOutlierColumn('kw_max_min',df,fact = 5)\n",
        "removingOutlierColumn('kw_avg_min',df,fact = 5)\n",
        "\n",
        "##  One-Hot Encoding\n",
        "df = pd.get_dummies(df, columns=['data_channel','weekday'])\n",
        "\n",
        "\n",
        "correlation_matrix = df.corr(method = 'spearman')\n",
        "top_10_values = correlation_matrix[\"shares\"].abs().nlargest(58)[1:]\n",
        "\n",
        "\n",
        "df.drop(top_10_values.index[11:],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9C-uSQy4pyj",
        "outputId": "10aea724-b47d-4b8c-f9cf-d9c98342026c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outliers in \"shares : 825\n",
            "-13095.0\n",
            "16740.0\n",
            "1755.0\n",
            "Number of outliers in \"kw_avg_avg : 673\n",
            "7.170798012573379\n",
            "8.760549506070774\n",
            "0.3974378733743489\n",
            "Number of outliers in \"self_reference_avg_sharess : 1376\n",
            "-15006.458333337501\n",
            "21185.16666667\n",
            "4021.2916666675\n",
            "Number of outliers in \"kw_avg_min : 635\n",
            "0.3828502486341421\n",
            "10.46816040955948\n",
            "0.91684637826594\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 27259 entries, 0 to 31714\n",
            "Data columns (total 12 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   kw_max_avg                  27259 non-null  float64\n",
            " 1   kw_avg_avg                  27259 non-null  float64\n",
            " 2   self_reference_min_shares   27259 non-null  float64\n",
            " 3   self_reference_max_shares   27259 non-null  float64\n",
            " 4   self_reference_avg_sharess  27259 non-null  float64\n",
            " 5   LDA_02                      27259 non-null  float64\n",
            " 6   shares                      27259 non-null  int64  \n",
            " 7   data_channel_entertainment  27259 non-null  uint8  \n",
            " 8   data_channel_socmed         27259 non-null  uint8  \n",
            " 9   data_channel_tech           27259 non-null  uint8  \n",
            " 10  data_channel_world          27259 non-null  uint8  \n",
            " 11  weekday_saturday            27259 non-null  uint8  \n",
            "dtypes: float64(6), int64(1), uint8(5)\n",
            "memory usage: 1.8 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RqvnRzIk5Dut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"shares\"]\n",
        "\n",
        "df.drop(\"shares\",axis=1,inplace=True)\n",
        "X = df\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_regressor = SVR(kernel = 'poly')\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "df[\"shares\"] = y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pCXI78N4wkR",
        "outputId": "3427a031-ba8b-4ed6-f08a-3b6e2aeb794c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 2509.560443075402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"shares\"]\n",
        "\n",
        "df.drop(\"shares\",axis=1,inplace=True)\n",
        "X = df\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_regressor = SVR(kernel = 'rbf')\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "df[\"shares\"] = y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq8ACNrV5gIi",
        "outputId": "2df45a71-754a-4d19-9380-a6ea524bb051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 2508.473901698801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"shares\"]\n",
        "df.drop(\"shares\",axis=1,inplace=True)\n",
        "X = df\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_regressor = GradientBoostingRegressor(random_state = 42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "df[\"shares\"] = y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M42Iwwg_-4q",
        "outputId": "6a89622b-08f2-4e34-cacb-f401534c7463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 2294.331919894945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"shares\"]\n",
        "\n",
        "df.drop(\"shares\",axis=1,inplace=True)\n",
        "X = df\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_regressor = RandomForestRegressor(300,max_depth=35,random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "df[\"shares\"] = y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKB2fTxxABBN",
        "outputId": "fc2b1934-1ba1-426c-b3a7-92a82317ce0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 2369.515935920455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"shares\"]\n",
        "\n",
        "df.drop(\"shares\",axis=1,inplace=True)\n",
        "X = df\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_regressor = LinearRegression()\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "df[\"shares\"] = y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uENh5GEcDVNd",
        "outputId": "9f82df93-1334-4508-ab5a-e95feee15dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 2301.983780900272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1KmqwKDGDLY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}